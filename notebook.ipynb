{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"../data-engineering/.JDK 8\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/25 20:48:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/03/25 20:48:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "import requests, json\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "        .appName(\"GreenDataAnalyticsProject\") \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url = \"https://maps2.bristol.gov.uk/server2/rest/services/ext/air_quality/MapServer/0/query?outFields=*&where=1%3D1&f=geojson\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(api_url)\n",
    "    geojson_data = response.json()\n",
    "except requests.exceptions.HTTPError as http_err:\n",
    "    # This block handles HTTP errors (e.g., 404, 500)\n",
    "    print(f\"HTTP error occurred: {http_err}\")\n",
    "\n",
    "except requests.exceptions.ConnectionError as conn_err:\n",
    "    # This block handles issues like network errors, no connection\n",
    "    print(f\"Connection error occurred: {conn_err}\")\n",
    "\n",
    "except requests.exceptions.Timeout as timeout_err:\n",
    "    # This block handles timeouts\n",
    "    print(f\"Timeout error occurred: {timeout_err}\")\n",
    "\n",
    "except requests.exceptions.RequestException as req_err:\n",
    "    # This block handles any other request-related errors\n",
    "    print(f\"An error occurred with the request: {req_err}\")\n",
    "\n",
    "except ValueError as json_err:\n",
    "    # This block handles errors related to JSON parsing\n",
    "    print(f\"Failed to parse JSON: {json_err}\")\n",
    "\n",
    "except Exception as e:\n",
    "    # This block handles any unexpected errors\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/25 20:48:57 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "features = geojson_data.get(\"features\", [])\n",
    "json_features = [json.dumps(feature) for feature in features]\n",
    "rdd = spark.sparkContext.parallelize(json_features)\n",
    "df = spark.read.json(rdd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select('id',\n",
    "    col('properties.location').alias('location'),\n",
    "    col('properties.LocationClass').alias('Location Type'),\n",
    "    df.geometry.coordinates.alias(\"coordinates\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+-------------+-----------------------------------------+\n",
      "|id |location        |Location Type|coordinates                              |\n",
      "+---+----------------+-------------+-----------------------------------------+\n",
      "|1  |Withywood School|Urban Traffic|[-2.6277488032062446, 51.407745517999835]|\n",
      "+---+----------------+-------------+-----------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"coordinates\", col(\"coordinates\")[1])\\\n",
    "    .withColumnRenamed(\"coordinates\", \"Latitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "max_value = df.agg(F.max('Latitude')).collect()[0][0]\n",
    "min_value = df.agg(F.min('Latitude')).collect()[0][0]\n",
    "\n",
    "def normalise(original_value):\n",
    "    scaled_value = (original_value - min_value) / (max_value - min_value)\n",
    "    return scaled_value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "normalise_udf = udf(normalise, DoubleType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+----------------+---------------------+\n",
      "|id |location         |Location Type   |Latitude (Normalised)|\n",
      "+---+-----------------+----------------+---------------------+\n",
      "|1  |Withywood School |Urban Traffic   |0.0909330382676792   |\n",
      "|2  |Colston Avenue   |Urban Traffic   |0.2938159127984107   |\n",
      "|3  |Blackboy Hill    |Urban Traffic   |0.357305528540315    |\n",
      "|4  |Three Lamps      |Urban Traffic   |0.2489726016785307   |\n",
      "|5  |Bedminster Parade|Urban Traffic   |0.2429141946354523   |\n",
      "|6  |Church Road      |Urban Traffic   |0.3102920364172479   |\n",
      "|7  |St. Andrew's Rd  |Urban Traffic   |0.49558147749590986  |\n",
      "|8  |Higham Street    |Urban Background|0.25101726499215116  |\n",
      "|9  |B.R.I.           |Urban Traffic   |0.312865051710554    |\n",
      "|10 |Bath Road        |Urban Traffic   |0.23296471427037527  |\n",
      "|11 |Whitefriars      |Urban Traffic   |0.3067735040613447   |\n",
      "|12 |Galleries        |Urban Traffic   |0.3017723316726845   |\n",
      "|13 |Ferndown Close   |Urban Background|0.46693403661442573  |\n",
      "|14 |Red Lion Knowle  |Urban Traffic   |0.18808863196323813  |\n",
      "|15 |Horsefair        |Urban Traffic   |0.31249761539385457  |\n",
      "|16 |Third Way        |Urban Traffic   |0.5132529966910423   |\n",
      "|17 |Anglesea Place   |Urban Traffic   |0.3545983028904187   |\n",
      "|18 |Hillcrest        |Urban Background|0.18027812662917475  |\n",
      "|19 |Conham Vale      |Urban Traffic   |0.2604651853675661   |\n",
      "|20 |Newfoundland Way |Urban Traffic   |0.31823336137020186  |\n",
      "+---+-----------------+----------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"Latitude (Normalised)\", normalise_udf(\"Latitude\")).drop(\"Latitude\")\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df.toPandas().to_csv(\"cleanedAirQualityData.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
