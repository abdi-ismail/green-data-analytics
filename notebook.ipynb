{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"JAVA_HOME\"] = \"../data-engineering/.JDK 8\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/29 14:15:08 WARN Utils: Your hostname, Mint-T470 resolves to a loopback address: 127.0.1.1; using 10.46.79.254 instead (on interface wlp4s0)\n",
      "25/03/29 14:15:08 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/29 14:15:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count\n",
    "import requests, json\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "        .appName(\"GreenDataAnalyticsProject\") \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apiaccess(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        geojson_data = response.json()\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"HTTP error occurred: {http_err}\")\n",
    "\n",
    "    except requests.exceptions.ConnectionError as conn_err:\n",
    "        print(f\"Connection error occurred: {conn_err}\")\n",
    "\n",
    "    except requests.exceptions.Timeout as timeout_err:\n",
    "        print(f\"Timeout error occurred: {timeout_err}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as req_err:\n",
    "        print(f\"An error occurred with the request: {req_err}\")\n",
    "\n",
    "    except ValueError as json_err:\n",
    "        print(f\"Failed to parse JSON: {json_err}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        \n",
    "    else:\n",
    "        features = geojson_data.get(\"features\", [])\n",
    "        json_features = [json.dumps(feature) for feature in features]\n",
    "        rdd = spark.sparkContext.parallelize(json_features)\n",
    "        dataframe = spark.read.json(rdd)\n",
    "        return(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/29 14:15:33 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "api_url = \"https://maps2.bristol.gov.uk/server2/rest/services/ext/air_quality/MapServer/0/query?outFields=*&where=1%3D1&f=geojson\"\n",
    "df = apiaccess(api_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+--------------------+-------+\n",
      "|            geometry| id|          properties|   type|\n",
      "+--------------------+---+--------------------+-------+\n",
      "|{[-2.627748803206...|  1|{Yes, NULL, No, N...|Feature|\n",
      "|{[-2.596813947482...|  2|{Yes, NULL, Yes, ...|Feature|\n",
      "|{[-2.613994167991...|  3|{No, NULL, Yes, N...|Feature|\n",
      "|{[-2.578333463205...|  4|{Yes, NULL, Yes, ...|Feature|\n",
      "|{[-2.595294420664...|  5|{Yes, NULL, Yes, ...|Feature|\n",
      "|{[-2.558965289247...|  6|{Yes, NULL, No, N...|Feature|\n",
      "|{[-2.697147645214...|  7|{No, NULL, No, NU...|Feature|\n",
      "|{[-2.579303486860...|  8|{Yes, NULL, No, N...|Feature|\n",
      "|{[-2.595417508199...|  9|{Yes, NULL, Yes, ...|Feature|\n",
      "|{[-2.559380932414...| 10|{Yes, NULL, Yes, ...|Feature|\n",
      "|{[-2.594190185154...| 11|{Yes, NULL, Yes, ...|Feature|\n",
      "|{[-2.589439954461...| 12|{Yes, NULL, Yes, ...|Feature|\n",
      "|{[-2.656900421884...| 13|{No, NULL, No, NU...|Feature|\n",
      "|{[-2.564144569808...| 14|{Yes, NULL, Yes, ...|Feature|\n",
      "|{[-2.587283945975...| 15|{Yes, NULL, Yes, ...|Feature|\n",
      "|{[-2.688839013557...| 16|{No, NULL, Yes, N...|Feature|\n",
      "|{[-2.616505262752...| 17|{No, NULL, No, NU...|Feature|\n",
      "|{[-2.566797603102...| 18|{No, NULL, No, NU...|Feature|\n",
      "|{[-2.534937419314...| 19|{No, NULL, No, NU...|Feature|\n",
      "|{[-2.583371342566...| 20|{Yes, NULL, No, N...|Feature|\n",
      "+--------------------+---+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select('id',\n",
    "               col('properties.SiteID').alias('SiteID'),\n",
    "    col('properties.location').alias('location'),\n",
    "    col('properties.LocationClass').alias('Location Type'),\n",
    "    df.geometry.coordinates.alias(\"coordinates\"),\n",
    "    col('properties.Pollutants').alias('Pollutants'),\n",
    "    col('properties.Elevation').alias('Elevation')\n",
    "    )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+-------------+-----------------------------------------+----------+---------+\n",
      "|id |SiteID|location        |Location Type|coordinates                              |Pollutants|Elevation|\n",
      "+---+------+----------------+-------------+-----------------------------------------+----------+---------+\n",
      "|1  |1     |Withywood School|Urban Traffic|[-2.6277488032062446, 51.407745517999835]|BTX NO2   |NULL     |\n",
      "+---+------+----------------+-------------+-----------------------------------------+----------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Longitude\", col(\"coordinates\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Latitude\", col(\"coordinates\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "max_value = df.agg(F.max('Latitude')).collect()[0][0]\n",
    "min_value = df.agg(F.min('Latitude')).collect()[0][0]\n",
    "\n",
    "def normalise(original_value):\n",
    "    try:\n",
    "        assert max_value > min_value, \"max_value must be larger than min_value\"\n",
    "        assert original_value > min_value, \"input must be larger than min_value\"\n",
    "        scaled_value = (original_value - min_value) / (max_value - min_value)\n",
    "    except AssertionError as e:\n",
    "        return e\n",
    "        \n",
    "    else:\n",
    "        return scaled_value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "normalise_udf = udf(normalise, DoubleType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----------------+----------------+-----------------------------------------+----------+---------+-------------------+------------------+---------------------+\n",
      "|id |SiteID|location         |Location Type   |coordinates                              |Pollutants|Elevation|Longitude          |Latitude          |Latitude (Normalised)|\n",
      "+---+------+-----------------+----------------+-----------------------------------------+----------+---------+-------------------+------------------+---------------------+\n",
      "|1  |1     |Withywood School |Urban Traffic   |[-2.6277488032062446, 51.407745517999835]|BTX NO2   |NULL     |-2.6277488032062446|51.407745517999835|0.0909330382676792   |\n",
      "|2  |2     |Colston Avenue   |Urban Traffic   |[-2.5968139474821794, 51.454556566902696]|NO2       |9.5      |-2.5968139474821794|51.454556566902696|0.2938159127984107   |\n",
      "|3  |3     |Blackboy Hill    |Urban Traffic   |[-2.613994167991525, 51.46920548941127]  |NO2       |79.2     |-2.613994167991525 |51.46920548941127 |0.357305528540315    |\n",
      "|4  |4     |Three Lamps      |Urban Traffic   |[-2.578333463205696, 51.444209895530584] |NO2       |26.6     |-2.578333463205696 |51.444209895530584|0.2489726016785307   |\n",
      "|5  |5     |Bedminster Parade|Urban Traffic   |[-2.595294420664777, 51.442812042759506] |NO2       |8.1      |-2.595294420664777 |51.442812042759506|0.2429141946354523   |\n",
      "|6  |6     |Church Road      |Urban Traffic   |[-2.558965289247974, 51.458358093425005] |NO2       |23.6     |-2.558965289247974 |51.458358093425005|0.3102920364172479   |\n",
      "|7  |7     |St. Andrew's Rd  |Urban Traffic   |[-2.6971476452140064, 51.50110981955063] |NO2       |6.8      |-2.6971476452140064|51.50110981955063 |0.49558147749590986  |\n",
      "|8  |8     |Higham Street    |Urban Background|[-2.579303486860559, 51.44468165952045]  |NO2       |35.8     |-2.579303486860559 |51.44468165952045 |0.25101726499215116  |\n",
      "|9  |9     |B.R.I.           |Urban Traffic   |[-2.5954175081992816, 51.45895176376313] |NO2       |19.9     |-2.5954175081992816|51.45895176376313 |0.312865051710554    |\n",
      "|10 |10    |Bath Road        |Urban Traffic   |[-2.5593809324143635, 51.440516404879745]|NO2       |20.3     |-2.5593809324143635|51.440516404879745|0.23296471427037527  |\n",
      "|11 |11    |Whitefriars      |Urban Traffic   |[-2.594190185154556, 51.45754626447907]  |NO2       |8.5      |-2.594190185154556 |51.45754626447907 |0.3067735040613447   |\n",
      "|12 |12    |Galleries        |Urban Traffic   |[-2.5894399544611586, 51.45639234685148] |NO2       |12.5     |-2.5894399544611586|51.45639234685148 |0.3017723316726845   |\n",
      "|13 |13    |Ferndown Close   |Urban Background|[-2.656900421884163, 51.49450001199961]  |NO2       |69.1     |-2.656900421884163 |51.49450001199961 |0.46693403661442573  |\n",
      "|14 |14    |Red Lion Knowle  |Urban Traffic   |[-2.5641445698086747, 51.43016217223045] |NO2       |60.6     |-2.5641445698086747|51.43016217223045 |0.18808863196323813  |\n",
      "|15 |15    |Horsefair        |Urban Traffic   |[-2.5872839459753796, 51.4588669853932]  |NO2       |10.3     |-2.5872839459753796|51.4588669853932  |0.31249761539385457  |\n",
      "|16 |16    |Third Way        |Urban Traffic   |[-2.688839013557719, 51.50518715900643]  |NO2       |7.6      |-2.688839013557719 |51.50518715900643 |0.5132529966910423   |\n",
      "|17 |17    |Anglesea Place   |Urban Traffic   |[-2.6165052627526926, 51.468580852794794]|NO2       |81.2     |-2.6165052627526926|51.468580852794794|0.3545983028904187   |\n",
      "|18 |18    |Hillcrest        |Urban Background|[-2.5667976031020703, 51.428360058828844]|NO2       |54.1     |-2.5667976031020703|51.428360058828844|0.18027812662917475  |\n",
      "|19 |19    |Conham Vale      |Urban Traffic   |[-2.5349374193143355, 51.44686157275239] |NO2       |13.5     |-2.5349374193143355|51.44686157275239 |0.2604651853675661   |\n",
      "|20 |20    |Newfoundland Way |Urban Traffic   |[-2.5833713425664975, 51.46019039076201] |NO2       |9.9      |-2.5833713425664975|51.46019039076201 |0.31823336137020186  |\n",
      "+---+------+-----------------+----------------+-----------------------------------------+----------+---------+-------------------+------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"Latitude (Normalised)\", normalise_udf(\"Latitude\")) # .drop(\"Latitude\")\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.toPandas().to_csv(\"cleanedAirQualityData.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
